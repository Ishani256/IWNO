{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZuvZ0Qm_hud"
      },
      "outputs": [],
      "source": [
        "pip install pytorch_wavelets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "get_ipython().magic('reset -sf')\n",
        "\n",
        "import pywt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from timeit import default_timer\n",
        "# from utilities3 import *\n",
        "from pytorch_wavelets import DWT1D, IDWT1D\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "metadata": {
        "id": "zVJsYAnPpdBU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the HDF5 dataset\n",
        "file_path = \"/content/Config_2_sample_obs_1pc.hdf5\"\n",
        "with h5py.File(file_path, \"r\") as hdf:\n",
        "    # Load input and output data\n",
        "    x_data = np.array(hdf[\"input\"])\n",
        "    y_data = np.array(hdf[\"output\"])\n",
        "\n",
        "# print(x_data.shape)\n",
        "# print(y_data.shape)\n"
      ],
      "metadata": {
        "id": "K70ftJRGsVzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LastConditionalBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(LastConditionalBlock, self).__init__()\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)  # Flatten except batch dimension\n",
        "\n",
        "        # Calculate flattened size dynamically\n",
        "        flattened_size = x.size(1)\n",
        "\n",
        "        # Define fully connected layer with dynamically calculated input size\n",
        "        fc = nn.Linear(flattened_size, 128)\n",
        "        x = fc(x)\n",
        "        return x\n",
        "\n",
        "class ConditionalNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConditionalNetwork, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(1, 64, kernel_size=3, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.last_block = LastConditionalBlock(in_channels=16)  # Adjust input channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = self.block1(x)\n",
        "        c1 = out1  # Store the original c1\n",
        "        out2 = self.block2(out1)\n",
        "        c2 = out2  # Store the original c2\n",
        "        out3 = self.block3(out2)\n",
        "        c3 = out3  # Store the original c3\n",
        "        out4 = self.last_block(out3)\n",
        "        c4 = out4  # Store the original c4\n",
        "\n",
        "        # Flatten the outputs to 2D\n",
        "        out1 = out1.view(out1.size(0), -1)\n",
        "        out2 = out2.view(out2.size(0), -1)\n",
        "        out3 = out3.view(out3.size(0), -1)\n",
        "        out4 = out4.view(out4.size(0), -1)\n",
        "\n",
        "        return out1, out2, out3, out4\n",
        "\n",
        "# # Initialize and forward pass through the conditional network\n",
        "conditional_net = ConditionalNetwork()\n",
        "y_data_tensor = torch.from_numpy(y_data).unsqueeze(1).float()\n",
        "c1, c2, c3, c4 = conditional_net(y_data_tensor)\n",
        "\n",
        "# print(\"c1 shape:\", c1.shape)\n",
        "# print(\"c2 shape:\", c2.shape)\n",
        "# print(\"c3 shape:\", c3.shape)\n",
        "# print(\"c4 shape:\", c4.shape)\n"
      ],
      "metadata": {
        "id": "UUYMTlx4s_Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import h5py\n",
        "import torch.nn as nn\n",
        "\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "\n",
        "\"\"\"\n",
        "This code is taken from the repo: https://github.com/zongyi-li/fourier_neural_operator\n",
        "\n",
        "The associated article is Fourier Neural Operator\n",
        "\"\"\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# reading data\n",
        "class MatReader(object):\n",
        "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
        "        super(MatReader, self).__init__()\n",
        "\n",
        "        self.to_torch = to_torch\n",
        "        self.to_cuda = to_cuda\n",
        "        self.to_float = to_float\n",
        "\n",
        "        self.file_path = file_path\n",
        "\n",
        "        self.data = None\n",
        "        self.old_mat = None\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            self.data = scipy.io.loadmat(self.file_path)\n",
        "            self.old_mat = True\n",
        "        except:\n",
        "            self.data = h5py.File(self.file_path)\n",
        "            self.old_mat = False\n",
        "\n",
        "    def load_file(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self._load_file()\n",
        "\n",
        "    def read_field(self, field):\n",
        "        x = self.data[field]\n",
        "\n",
        "        if not self.old_mat:\n",
        "            x = x[()]\n",
        "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
        "\n",
        "        if self.to_float:\n",
        "            x = x.astype(np.float32)\n",
        "\n",
        "        if self.to_torch:\n",
        "            x = torch.from_numpy(x)\n",
        "\n",
        "            if self.to_cuda:\n",
        "                x = x.cuda()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_cuda(self, to_cuda):\n",
        "        self.to_cuda = to_cuda\n",
        "\n",
        "    def set_torch(self, to_torch):\n",
        "        self.to_torch = to_torch\n",
        "\n",
        "    def set_float(self, to_float):\n",
        "        self.to_float = to_float\n",
        "\n",
        "# normalization, pointwise gaussian\n",
        "class UnitGaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(UnitGaussianNormalizer, self).__init__()\n",
        "\n",
        "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
        "        self.mean = torch.mean(x, 0)\n",
        "        self.std = torch.std(x, 0)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        if sample_idx is None:\n",
        "            std = self.std + self.eps # n\n",
        "            mean = self.mean\n",
        "        else:\n",
        "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
        "                std = self.std[sample_idx] + self.eps  # batch*n\n",
        "                mean = self.mean[sample_idx]\n",
        "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
        "                std = self.std[:,sample_idx]+ self.eps # T*batch*n\n",
        "                mean = self.mean[:,sample_idx]\n",
        "\n",
        "        # x is in shape of batch*n or T*batch*n\n",
        "        x = (x * std) + mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "\n",
        "# normalization, Gaussian\n",
        "class GaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(GaussianNormalizer, self).__init__()\n",
        "\n",
        "        self.mean = torch.mean(x)\n",
        "        self.std = torch.std(x)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        x = (x * (self.std + self.eps)) + self.mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "\n",
        "\n",
        "# normalization, scaling by range\n",
        "class RangeNormalizer(object):\n",
        "    def __init__(self, x, low=0.0, high=1.0):\n",
        "        super(RangeNormalizer, self).__init__()\n",
        "        mymin = torch.min(x, 0)[0].view(-1)\n",
        "        mymax = torch.max(x, 0)[0].view(-1)\n",
        "\n",
        "        self.a = (high - low)/(mymax - mymin)\n",
        "        self.b = -self.a*mymax + high\n",
        "\n",
        "    def encode(self, x):\n",
        "        s = x.size()\n",
        "        x = x.view(s[0], -1)\n",
        "        x = self.a*x + self.b\n",
        "        x = x.view(s)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x):\n",
        "        s = x.size()\n",
        "        x = x.view(s[0], -1)\n",
        "        x = (x - self.b)/self.a\n",
        "        x = x.view(s)\n",
        "        return x\n",
        "\n",
        "#loss function with rel/abs Lp loss\n",
        "class LpLoss(object):\n",
        "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
        "        super(LpLoss, self).__init__()\n",
        "\n",
        "        #Dimension and Lp-norm type are postive\n",
        "        assert d > 0 and p > 0\n",
        "\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.reduction = reduction\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def abs(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        #Assume uniform mesh\n",
        "        h = 1.0 / (x.size()[1] - 1.0)\n",
        "\n",
        "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(all_norms)\n",
        "            else:\n",
        "                return torch.sum(all_norms)\n",
        "\n",
        "        return all_norms\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(diff_norms/y_norms)\n",
        "            else:\n",
        "                return torch.sum(diff_norms/y_norms)\n",
        "\n",
        "        return diff_norms/y_norms\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        return self.rel(x, y)\n",
        "\n",
        "# Sobolev norm (HS norm)\n",
        "# where we also compare the numerical derivatives between the output and target\n",
        "class HsLoss(object):\n",
        "    def __init__(self, d=2, p=2, k=1, a=None, group=False, size_average=True, reduction=True):\n",
        "        super(HsLoss, self).__init__()\n",
        "\n",
        "        #Dimension and Lp-norm type are postive\n",
        "        assert d > 0 and p > 0\n",
        "\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.k = k\n",
        "        self.balanced = group\n",
        "        self.reduction = reduction\n",
        "        self.size_average = size_average\n",
        "\n",
        "        if a == None:\n",
        "            a = [1,] * k\n",
        "        self.a = a\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(diff_norms/y_norms)\n",
        "            else:\n",
        "                return torch.sum(diff_norms/y_norms)\n",
        "        return diff_norms/y_norms\n",
        "\n",
        "    def __call__(self, x, y, a=None):\n",
        "        nx = x.size()[1]\n",
        "        ny = x.size()[2]\n",
        "        k = self.k\n",
        "        balanced = self.balanced\n",
        "        a = self.a\n",
        "        x = x.view(x.shape[0], nx, ny, -1)\n",
        "        y = y.view(y.shape[0], nx, ny, -1)\n",
        "\n",
        "        k_x = torch.cat((torch.arange(start=0, end=nx//2, step=1),torch.arange(start=-nx//2, end=0, step=1)), 0).reshape(nx,1).repeat(1,ny)\n",
        "        k_y = torch.cat((torch.arange(start=0, end=ny//2, step=1),torch.arange(start=-ny//2, end=0, step=1)), 0).reshape(1,ny).repeat(nx,1)\n",
        "        k_x = torch.abs(k_x).reshape(1,nx,ny,1).to(x.device)\n",
        "        k_y = torch.abs(k_y).reshape(1,nx,ny,1).to(x.device)\n",
        "\n",
        "        x = torch.fft.fftn(x, dim=[1, 2])\n",
        "        y = torch.fft.fftn(y, dim=[1, 2])\n",
        "\n",
        "        if balanced==False:\n",
        "            weight = 1\n",
        "            if k >= 1:\n",
        "                weight += a[0]**2 * (k_x**2 + k_y**2)\n",
        "            if k >= 2:\n",
        "                weight += a[1]**2 * (k_x**4 + 2*k_x**2*k_y**2 + k_y**4)\n",
        "            weight = torch.sqrt(weight)\n",
        "            loss = self.rel(x*weight, y*weight)\n",
        "        else:\n",
        "            loss = self.rel(x, y)\n",
        "            if k >= 1:\n",
        "                weight = a[0] * torch.sqrt(k_x**2 + k_y**2)\n",
        "                loss += self.rel(x*weight, y*weight)\n",
        "            if k >= 2:\n",
        "                weight = a[1] * torch.sqrt(k_x**4 + 2*k_x**2*k_y**2 + k_y**4)\n",
        "                loss += self.rel(x*weight, y*weight)\n",
        "            loss = loss / (k+1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "# print the number of parameters\n",
        "def count_params(model):\n",
        "    c = 0\n",
        "    for p in list(model.parameters()):\n",
        "        c += reduce(operator.mul,\n",
        "                    list(p.size()+(2,) if p.is_complex() else p.size()))\n",
        "    return c"
      ],
      "metadata": {
        "id": "XBXFSRlacXWy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lhQgy1C_rXFJ"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "\"\"\" Def: 1d Wavelet layer \"\"\"\n",
        "class WaveConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, level, dummy):\n",
        "        super(WaveConv1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        1D Wavelet layer. It does Wavelet Transform, linear transform, and\n",
        "        Inverse Wavelet Transform.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.level = level\n",
        "        self.dwt_ = DWT1D(wave='db6', J=self.level, mode='symmetric').to(dummy.device)\n",
        "        self.mode_data, _ = self.dwt_(dummy)\n",
        "        self.modes1 = self.mode_data.shape[-1]\n",
        "\n",
        "        self.scale = (1 / (in_channels*out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1))\n",
        "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1))\n",
        "\n",
        "    # Convolution\n",
        "    def mul1d(self, input, weights):\n",
        "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
        "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        # Compute single tree Discrete Wavelet coefficients using some wavelet\n",
        "        dwt = DWT1D(wave='db6', J=self.level, mode='symmetric').to(device)\n",
        "        x_ft, x_coeff = dwt(x)\n",
        "\n",
        "        # Multiply the final low pass and high pass coefficients\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels, x_ft.shape[-1],  device=x.device)\n",
        "        out_ft = self.mul1d(x_ft, self.weights1)\n",
        "        x_coeff[-1] = self.mul1d(x_coeff[-1], self.weights2)\n",
        "\n",
        "        # Reconstruct the signal\n",
        "        idwt = IDWT1D(wave='db6', mode='symmetric').to(device)\n",
        "        x = idwt((out_ft, x_coeff))\n",
        "        return x\n",
        "\n",
        "\"\"\" The forward operation \"\"\"\n",
        "class WNO1d(nn.Module):\n",
        "    def __init__(self,in_features, hidden_dim=256, width=64, level=4, x_train=None):\n",
        "        super(WNO1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The WNO network. It contains 4 layers of the Wavelet integral layer.\n",
        "        1. Lift the input using v(x) = self.fc0 .\n",
        "        2. 4 layers of the integral operators v(+1) = g(K(.) + W)(v).\n",
        "            W is defined by self.w_; K is defined by self.conv_.\n",
        "        3. Project the output of last layer using self.fc1 and self.fc2.\n",
        "\n",
        "        input: the solution of the initial condition and location (a(x), x)\n",
        "        input shape: (batchsize, x=s, c=2)\n",
        "        output: the solution of a later timestep\n",
        "        output shape: (batchsize, x=s, c=1)\n",
        "        \"\"\"\n",
        "        self.in_features = in_features\n",
        "        self.level = level\n",
        "        self.width = width\n",
        "        self.dummy_data = dummy_data\n",
        "        self.padding = 2 # pad the domain when required\n",
        "        self.fc0 = nn.Linear(in_features+1, self.width) # input channel is 2: (a(x), x)\n",
        "\n",
        "        self.conv0 = WaveConv1d(self.width, self.width, self.level, self.dummy_data)\n",
        "        self.conv1 = WaveConv1d(self.width, self.width, self.level, self.dummy_data)\n",
        "        self.conv2 = WaveConv1d(self.width, self.width, self.level, self.dummy_data)\n",
        "        self.conv3 = WaveConv1d(self.width, self.width, self.level, self.dummy_data)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        # x = F.pad(x, [0,self.padding])\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "\n",
        "        # x = x[..., :-self.padding]\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        # The grid of the solution\n",
        "        batchsize, size_x = shape[0], shape[1]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1).repeat([batchsize, 1, 1])\n",
        "        return gridx.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RealNVPBlock(nn.Module):\n",
        "    def __init__(self, in_features, hidden_dim=256, width=64, level=4, x_train=None):\n",
        "        super(RealNVPBlock, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Define the scale and translation networks\n",
        "        self.scale_net = WNO1d(in_features, hidden_dim, width, level, x_train.permute(0, 2, 1))\n",
        "        self.translation_net = WNO1d(in_features, hidden_dim,width, level, x_train.permute(0, 2, 1))\n",
        "\n",
        "    def forward(self, x1, x2, c1):\n",
        "        # Ensure x1 has the correct shape\n",
        "        x1 = x1.unsqueeze(1)  # Add a channel dimension\n",
        "        x1_concat_c1 = torch.cat((x1, c1.unsqueeze(1)), dim=-1)\n",
        "        # Compute scale and translation parameters\n",
        "        s = self.scale_net(x1)\n",
        "        t = self.translation_net(x1)\n",
        "\n",
        "        # Apply scale and translation to x2\n",
        "        x2_transformed = x2 * torch.exp(s) + t\n",
        "\n",
        "        # Return transformed x1 and x2\n",
        "        return x1.squeeze(1), x2_transformed\n",
        "\n",
        "    def inverse(self, y1, y2, c4):\n",
        "        # Ensure the sizes of tensors match for concatenation\n",
        "        if y1.size(-1) != c4.size(-1):\n",
        "            # Expand c4 to match the shape of y1\n",
        "            c4_expanded = c4.unsqueeze(1).expand(-1, y1.size(1), -1)\n",
        "        else:\n",
        "            c4_expanded = c4.unsqueeze(1)\n",
        "\n",
        "        # Concatenate y1 with c4\n",
        "        y1_concat_c4 = torch.cat((y1, c4_expanded), dim=-1)\n",
        "\n",
        "        # Define the scale and translation networks for the inverse pass\n",
        "        scale_net_inv = WNO1d(y1_concat_c4.size(-1), self.hidden_dim, width=64, level=4, x_train=y1_concat_c4)\n",
        "        translation_net_inv = WNO1d(y1_concat_c4.size(-1), self.hidden_dim, width=64, level=4, x_train=y1_concat_c4)\n",
        "\n",
        "        # Compute inverse scale and translation parameters\n",
        "        inv_s = scale_net_inv(y1_concat_c4)\n",
        "        inv_t = translation_net_inv(y1_concat_c4)\n",
        "\n",
        "        # Apply inverse scale and translation to y2\n",
        "        x2_inverse = (y2 - inv_t) * torch.exp(-inv_s)\n",
        "\n",
        "        # Return transformed x1 and x2\n",
        "        return y1.squeeze(1), x2_inverse\n"
      ],
      "metadata": {
        "id": "7EkMZUcsVMLw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class RealNVPBlock_fnn(nn.Module):\n",
        "    def __init__(self, in_features, c4_features, hidden_dim=256):\n",
        "        super(RealNVPBlock_fnn, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.c4_features = c4_features\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Define the scale and translation networks\n",
        "        self.scale_net = nn.Sequential(\n",
        "            nn.Linear(in_features + c4_features, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, in_features)\n",
        "        )\n",
        "\n",
        "        self.translation_net = nn.Sequential(\n",
        "            nn.Linear(in_features + c4_features, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2, c4):\n",
        "        # Ensure x1 has the correct shape\n",
        "        x1 = x1.unsqueeze(1)  # Add a channel dimension\n",
        "\n",
        "        # Concatenate x1 with c4\n",
        "        x1_concat_c4 = torch.cat((x1, c4.unsqueeze(1)), dim=-1)\n",
        "\n",
        "        # Compute scale and translation parameters\n",
        "        s = self.scale_net(x1_concat_c4)\n",
        "        t = self.translation_net(x1_concat_c4)\n",
        "\n",
        "        # Apply scale and translation to x2\n",
        "        x2_transformed = x2 * torch.exp(s) + t\n",
        "\n",
        "        # Return transformed x1 and x2\n",
        "        return x1.squeeze(1), x2_transformed\n",
        "\n",
        "    def inverse(self, y_data, c4):\n",
        "        # Ensure y_data has the correct shape\n",
        "        c4_reshaped = c4.repeat(1, y_data.shape[1], 1)\n",
        "\n",
        "        # Concatenate y_data with c4\n",
        "        y_data_concat_c4 = torch.cat((y_data, c4_reshaped), dim=-1)\n",
        "\n",
        "        # Flatten the concatenated tensor\n",
        "        y_data_concat_flat = y_data_concat_c4.view(y_data_concat_c4.size(0), -1)\n",
        "\n",
        "        # Define the scale and translation networks for the inverse pass\n",
        "        scale_net_inv = nn.Sequential(\n",
        "            nn.Linear(y_data_concat_flat.shape[1], self.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_dim, 256)  # Output size should match the last dimension of y_data\n",
        "        )\n",
        "\n",
        "        translation_net_inv = nn.Sequential(\n",
        "            nn.Linear(y_data_concat_flat.shape[1], self.hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(self.hidden_dim, 256)  # Output size should match the last dimension of y_data\n",
        "        )\n",
        "\n",
        "        # Compute inverse scale and translation parameters\n",
        "        inv_s = scale_net_inv(y_data_concat_flat)\n",
        "        inv_t = translation_net_inv(y_data_concat_flat)\n",
        "\n",
        "        # print(inv_s.shape)\n",
        "        # Reshape inv_s and inv_t to match the shape of y_data\n",
        "        inv_s = inv_s.view(y_data.shape[0], y_data.shape[1], -1)\n",
        "        inv_t = inv_t.view(y_data.shape[0], y_data.shape[1], -1)\n",
        "        # print(\"inv_s\",inv_s)\n",
        "        # print(\"Shapes - y_data:\", y_data.shape, \"inv_s:\", inv_s.shape, \"inv_t:\", inv_t.shape)\n",
        "\n",
        "        # Apply inverse scale and translation to y_data\n",
        "        x2_inverse = (y_data - inv_t) * torch.exp(-inv_s)\n",
        "\n",
        "        # Return transformed x1 and x2\n",
        "        return y_data.squeeze(1), x2_inverse\n"
      ],
      "metadata": {
        "id": "aWJr4vWPsjYM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with inverse pass and customized loss calculation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "x_data = torch.tensor(x_data, dtype=torch.float).unsqueeze(-1)\n",
        "x_data = x_data.view(1, 4096, 1)\n",
        "y_data = torch.tensor(y_data, dtype=torch.float)\n",
        "# print(x_data.shape)\n",
        "# Reshape the tensor from (1, 4096, 1) to (1, 4096)\n",
        "x_data_reshaped = x_data.view(1, 4096)\n",
        "\n",
        "# Split the tensor into two tensors of shapes (1, 2048) each\n",
        "x1 = x_data_reshaped[:, :2048]\n",
        "x2 = x_data_reshaped[:, 2048:]\n",
        "\n",
        "# Printing shapes for verification\n",
        "# print(\"Shape of x1:\", x1.shape)\n",
        "# print(\"Shape of x2:\", x2.shape)\n"
      ],
      "metadata": {
        "id": "_LIJNEdqa_xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "x_data = torch.tensor(x_data, dtype=torch.float).unsqueeze(-1)\n",
        "y_data = torch.tensor(y_data, dtype=torch.float)\n",
        "\n",
        "\n",
        "x_data_res = x_data.squeeze(-1)\n",
        "dummy_data = x_data_res\n",
        "train_dataset = TensorDataset(x_data, y_data)\n",
        "batch_size = 16  # Adjust batch size as needed\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define your RealNVP blocks\n",
        "block1 = RealNVPBlock(in_features=2048, x_train=x_data_res)\n",
        "block2 = RealNVPBlock(in_features=2048, x_train=x_data_res)\n",
        "block3 = RealNVPBlock(in_features=2048, x_train=x_data_res)\n",
        "block4 = RealNVPBlock(in_features=2048, x_train=x_data_res)\n",
        "block4_inv = RealNVPBlock_fnn(in_features=768, c4_features=128)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer1 = optim.Adam(block1.parameters(), lr=1e-4)  # Adjust learning rate as needed\n",
        "optimizer2 = optim.Adam(block2.parameters(), lr=1e-4)\n",
        "optimizer3 = optim.Adam(block3.parameters(), lr=1e-4)\n",
        "optimizer4 = optim.Adam(block4_inv.parameters(), lr=1e-4)\n",
        "loss_function = nn.SmoothL1Loss()\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler1 = ReduceLROnPlateau(optimizer1, mode='min', patience=5, factor=0.1, verbose=True)\n",
        "scheduler2 = ReduceLROnPlateau(optimizer2, mode='min', patience=5, factor=0.1, verbose=True)\n",
        "scheduler3 = ReduceLROnPlateau(optimizer3, mode='min', patience=5, factor=0.1, verbose=True)\n",
        "scheduler4 = ReduceLROnPlateau(optimizer4, mode='min', patience=5, factor=0.1, verbose=True)\n",
        "\n",
        "# Regularization\n",
        "weight_decay = 1e-5\n",
        "reg1 = torch.optim.lr_scheduler.LambdaLR(optimizer1, lambda epoch: 1 / (1 + weight_decay * epoch))\n",
        "reg2 = torch.optim.lr_scheduler.LambdaLR(optimizer2, lambda epoch: 1 / (1 + weight_decay * epoch))\n",
        "reg3 = torch.optim.lr_scheduler.LambdaLR(optimizer3, lambda epoch: 1 / (1 + weight_decay * epoch))\n",
        "reg4 = torch.optim.lr_scheduler.LambdaLR(optimizer4, lambda epoch: 1 / (1 + weight_decay * epoch))\n",
        "\n",
        "# Training loop with inverse pass and customized loss calculation\n",
        "num_epochs = 500  # Adjust number of epochs as needed\n",
        "log_interval = 100\n",
        "output_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    block1.train()\n",
        "    block2.train()\n",
        "    block3.train()\n",
        "    block4.train()\n",
        "    total_output_loss = 0\n",
        "\n",
        "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        # Forward pass\n",
        "        x1_out, x2_out = block1(x1, x2, c1)\n",
        "        x1_out_2, x2_out_2 = block2(x1_out, x2_out, c2)\n",
        "        x1_out_3, x2_out_3 = block3(x1_out_2, x2_out_2, c3)\n",
        "        x1_out_4, x2_out_4 = block4(x1_out_3, x2_out_3, c4)\n",
        "        y1_inverse, y2_inverse = block4_inv.inverse(y_data, c4)\n",
        "        y1_inverse_3, y2_inverse_3 = block3.inverse(y1_inverse, y2_inverse, c3)\n",
        "        y1_inverse_2, y2_inverse_2 = block2.inverse(y1_inverse_3, y2_inverse_3, c2)\n",
        "        y1_inverse_1, y2_inverse_1 = block1.inverse(y1_inverse_2, y2_inverse_2, c1)\n",
        "\n",
        "        # Concatenate y1_inverse_1 and y2_inverse_1 along the first dimension\n",
        "        concatenated_inverse = torch.cat((y1_inverse_1, y2_inverse_1), dim=1)\n",
        "\n",
        "        # Compute output loss\n",
        "        output_loss = loss_function(concatenated_inverse, x_batch[:, 2048:])\n",
        "        total_output_loss += output_loss.item()\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer1.zero_grad()\n",
        "        optimizer2.zero_grad()\n",
        "        optimizer3.zero_grad()\n",
        "        optimizer4.zero_grad()\n",
        "        output_loss.backward(retain_graph=True)\n",
        "\n",
        "        # # Gradient clipping\n",
        "        # clip_grad_norm_(block1.parameters(), max_norm=1)\n",
        "        # clip_grad_norm_(block2.parameters(), max_norm=1)\n",
        "        # clip_grad_norm_(block3.parameters(), max_norm=1)\n",
        "        # clip_grad_norm_(block4.parameters(), max_norm=1)\n",
        "        # clip_grad_norm_(block4_inv.parameters(), max_norm=1)\n",
        "\n",
        "        optimizer1.step()\n",
        "        optimizer2.step()\n",
        "        optimizer3.step()\n",
        "        optimizer4.step()\n",
        "        plt.figure(figsize=(10,5))\n",
        "\n",
        "        # Iterate over each batch\n",
        "        for i in range(min(x_batch.size(0), concatenated_inverse.size(0))):\n",
        "            m = x_batch[i, 2048:2048+512].detach().numpy().reshape(-1)\n",
        "            n = (concatenated_inverse[i, :512].detach().numpy().reshape(-1))\n",
        "            plt.plot(m[300:], label=f'Actual Input Batch {i}')\n",
        "            plt.plot(n[300:], label=f'Concatenated Inverse Batch {i}')\n",
        "\n",
        "        plt.title('Comparison between Actual Input and Concatenated Inverse')\n",
        "        plt.xlabel('Index')\n",
        "        plt.ylabel('Value')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # plt.xlim(0, 512)  # Set the limits for the x-axis (index)\n",
        "        # plt.ylim(-5, 5)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    # Learning rate scheduling\n",
        "    scheduler1.step(total_output_loss)\n",
        "    scheduler2.step(total_output_loss)\n",
        "    scheduler3.step(total_output_loss)\n",
        "    scheduler4.step(total_output_loss)\n",
        "\n",
        "    # Regularization\n",
        "    reg1.step()\n",
        "    reg2.step()\n",
        "    reg3.step()\n",
        "    reg4.step()\n",
        "\n",
        "\n",
        "\n",
        "    output_losses.append(total_output_loss / len(train_loader))\n",
        "    print('Epoch {} Average Output Loss: {:.6f}'.format(epoch+1, output_losses[-1]))\n"
      ],
      "metadata": {
        "id": "m0hWx-ltKuV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}